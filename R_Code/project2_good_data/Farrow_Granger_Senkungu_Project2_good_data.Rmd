---
title: "Stats 2 Project 2"
author: "Rick Farrow, Bruce Granger, TQ Senkungu"
date: "12/1/2018"
output:
    html_document:
        keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Required Libraries
- Tidyverse 
- Amelia
- Corrplot
- PSCL
- ROCR
- MASS
- car
- ggfortify

```{r Load_Libraries, include=FALSE}
# function to install any missing packages if needd to run knitr

install.if.nec <- function(x){
  for( i in x ){
    #  require returns TRUE invisibly if it was able to load package
    if( ! require( i , character.only = TRUE ) ){
      #  If package was not able to be loaded then re-install
      install.packages( i , dependencies = TRUE, repos = "http://cran.us.r-project.org")
      #  Load package after installing
      require( i , character.only = TRUE )
    }
  }
}

#  Try/install necessary packages
# Use this function wherever you make use of other packages.
install.if.nec( c("tidyverse", "Amelia", "corrplot", "pscl", "ROCR", "MASS", "car", "ggfortify","glmnet" ) )
#  Try/install necessary packages

library(ROCR)
library(MASS)
library(tidyverse)
library(Amelia)
library(corrplot)
library(pscl)
library(car)
library(ggfortify)
library(glmnet)

rm(install.if.nec)
```

## Load Data

- We are using the Breast Cancer Data from the Wisconsin Diagnostic Breast Cancer (WDBC) dataset and will first load it.

```{r input_data}
wdbc_data <- read.csv("https://raw.githubusercontent.com/tikisen/6372_proj2/master/Data/wdbc.data.csv", 
                      sep = ",", 
                      row.names = NULL, 
                      header = TRUE,
                      na.strings = c(""),
                      stringsAsFactors = FALSE)

wdbc.data <- wdbc_data

wdbc.data <- wdbc.data %>% dplyr::select(ID_number = 1, everything())
wdbc.sub <- wdbc.data %>% dplyr::select(1:12)

wdbc_data <- wdbc_data %>% dplyr::select(ID_number = 1, everything())
wdbc_sub <- wdbc_data %>% dplyr::select(1:12)
wdbc_sub <- wdbc_sub %>% dplyr::mutate(dia = dplyr::case_when(diagnosis == "B" ~ 0,
                                                  diagnosis == "M" ~ 1)) %>%
 dplyr::select(1, 3:13) %>% dplyr::select(1, diagnosis = dia, 2:11)

```

# Bruce's Work Starts Here

## Check for missing values
```{r CheckForMissingValues}
sapply(wdbc_data,function(x) sum(is.na(x)))
```

- The above output identifies there is not any missing data in any of the attributes.

## Summary Statistics/Histograms
```{r SummaryStats}
# TOTAL COUNT BY CANCER TYPE ####

ggplot(data=wdbc.sub, aes(x=diagnosis, colour = diagnosis)) +
  geom_bar() +
  geom_text(stat='Count', aes(label=..count..), vjust = 10) +
  theme(legend.position = "none") +
  scale_color_manual(values = c("blue", "red")) +
  ggtitle("Total Count by Cancer Type: Blue = Benign; Red = Malignant ") 
  

# PERCENT OF TOTAL BY CANCER TYPE ####
wdbc.sub.percent <- wdbc.sub %>% 
  count(diagnosis) %>% 
  mutate(perc = n / nrow(wdbc.sub))

ggplot(data=wdbc.sub.percent, aes(x = diagnosis, y = perc, colour = diagnosis)) +
  geom_bar(stat = "identity") +
  geom_text(stat = "identity", aes(label=round(perc*100,2)), vjust = 10) +
  theme(legend.position = "none") +
  scale_color_manual(values = c("blue", "red")) +
  ggtitle("Percent of Total by Cancer Type: Blue = Benign; Red = Malignant ")
rm(wdbc.sub.percent) 
```

- Ideally, the proportion of events and non-events in the Y variable should approximately be the same.
- From the above histograms it is obvious there is a class bias, a condition observed when the Malignant proportion of events is much smaller than proportion of Benign events, by a factor of 1 to 1.68.  
- As a result, we must sample the observations in approximately equal proportions in order to get better model.  Unfortunately we have a small sample size, which means we are not able to implement this strategy. 
 
## Pairs Plots
- Version 1:
- The objective of the "Pairs Plot" is to create plots based upon paring of variables
- Additionaly, each observation is color coded to simutaleniously see if the observation is "Benign" or "Malignant " cancer.  
  - Color Coding:
    * Blue = Benign 
    * Red = Malignant 

```{r pairsplot_ver1}
ed.small <- wdbc_sub %>% dplyr::select(-c(1))

cols <- character(nrow(ed.small))
cols[] <- "black"
cols[ed.small$diagnosis == 0] <- "blue"
cols[ed.small$diagnosis == 1] <- "red"
pairs(ed.small, col=cols, main = "WDBC Pairs Plot: Blue = Benign; Red = Malignant")
rm(cols)
rm(ed.small)
```

- Version 2:
- Similar to the first Pairs Plot, however version 2 introduces jitter to the observations and as a result it is easy to see the density of the observations.

```{r pairsplot_ver2}
ed.small <- wdbc_sub %>% dplyr::select(-c(1))
# the alpha argument in rgb() lets you set the transparency
cols2 = c(rgb(red=0, green=0, blue=255, alpha=50, maxColorValue=255), 
          rgb(red=255, green=0, blue=0, alpha=50, maxColorValue=255))
cols2 = ifelse(ed.small$diagnosis==0, cols2[1], cols2[2])

# here we jitter the data
set.seed(6141)  # this makes the example exactly reproducible
jbreast = apply(ed.small[,2:11], 2, FUN=function(x){ jitter(x, amount=.5) })
jbreast = cbind(jbreast, class=ed.small[,11])  # the class variable is not jittered

#windows()  # to match up the 1st & 2nd sets requires more coding
layout(matrix(1:25, nrow=5, byrow=T))
par(mar=c(.5,.5,.5,.5), oma=c(2,2,2,2))

for(i in 1:5){
   for(j in 6:10){
    
    plot(jbreast[,j], jbreast[,i], col=cols2, pch=16,
         
         axes=F, main="", xlab="", ylab="")
    
    box()
    
    if(j==6 ){ mtext(colnames(jbreast)[i], side=2, cex=.7, line=1) }
    
    if(i==5 ){ mtext(colnames(jbreast)[j], side=1, cex=.7, line=1) }
    
    if(j==10){ axis(side=4, seq(2,10,2), cex.axis=.8) }
    
    if(i==1 ){ axis(side=3, seq(2,10,2), cex.axis=.8) }
    
  }
  
}
rm(list = c("jbreast", "cols2", "i", "j"))

```

## Corrleation Plot
- Positive correlations are displayed in blue and negative correlations in red color.
- Color intensity and the size of the circle are proportional to the correlation coefficients.

```{r CorrelationPlot}
ed.small <- wdbc.sub %>% dplyr::select(-c(1,2))
corr <- cor(ed.small)

corrplot(corr, method ="number", type= "upper")
corrplot(corr, method ="circle", type= "upper")
rm(list = c("corr", "ed.small"))
```

- The largest Pos correlations:

- The largest Neg correlations:

## Scatter Plot
- Attributes vs diagnosis with Sep
  - Area
  - Compactness
  - Concave Points
  - Concavity
  - Perimeter
  - Radius
  - Texture
```{r ScatterVarVsDiag}
ed.small <- wdbc_sub %>% select(diagnosis ,area, compactness, concave_points, 
                                concavity, perimeter, radius, texture)

ed.tall <- ed.small %>% gather(-diagnosis, key = "variable", value = "value")


ggplot(data = ed.tall, aes(x=value, y=diagnosis)) +
  geom_point(aes(colour =  diagnosis)) +
  geom_jitter(aes(colour =  diagnosis)) +
  facet_wrap(~variable, scales = "free", ncol = 4)

ggplot(data = ed.tall, aes(x=value, y=diagnosis)) +
  geom_point(aes(colour =  diagnosis)) +
  geom_jitter(aes(colour =  diagnosis)) +
  facet_grid(~variable, scales = "free")
  
  
# geom_point(aes(colour =  diagnosis), shape = 1) +
#   scale_colour_gradientn(colours = c("blue", "red")) +
#   facet_wrap(~variable, scales = "free", ncol = 4) +
#   ggtitle("Scatter: Variables vs Diagnosis") +
#   geom_jitter()
  
  
  # facet_wrap(~variable, scales = "free", ncol = 4) +
  # ggtitle("Scatter: Variables vs Diagnosis") 
  # 
  # scale_color_manual(values = c("blue", "red"))


ed.small <- wdbc_sub %>% select(fractal_dimension, smoothness, symmetry)
  
  ## CIRCLE BACK

rm(list = c("ed.small", "ed.tall"))
```

## Histogram
- The histograms are a look at each attribute broken down by CancerState

```{r histogram}
ed.tall <- wdbc.sub %>% dplyr::select(-c(1)) %>%
  gather(-1, key = "Variable", value = "Value") 

ggplot(data = ed.tall, aes(x=Value)) +
  geom_histogram(bins=15) + 
  facet_wrap(Variable ~ diagnosis, ncol = 5, scales = "free")
rm(ed.tall)
```

## Boxplots
- Boxplot of attributes, color by CancerState

```{r Boxplot}
ed.tall <- wdbc.sub %>% dplyr::select(-c(1)) %>%
  gather(-1, key = "Variable", value = "Value") 

ggplot(ed.tall, aes(x=diagnosis, y=Value, fill = diagnosis)) + 
  geom_boxplot() +
  facet_wrap(~ Variable, scales = "free") +
  ggtitle("WDBC Boxplot ") + 
  scale_fill_manual(breaks = c("Benign", "Malignant "), values = c("blue", "red")) +
  theme(legend.position="none")
rm(ed.tall)
```
## Training and Test Datasets
```{r TrainAndTest}
set.seed(12345) #to get repeatable data
 
wdbc.train <- sample_frac(wdbc.sub, 0.8, replace = FALSE)
train.index <- as.numeric(rownames(wdbc.train))
wdbc.test <- wdbc.sub[-train.index,]

wdbc_train <- wdbc_sub[train.index,]
wdbc_test <- wdbc_sub[-train.index,]

rm(train.index)

```

## Model - VIF
```{r VIFModel}
glm_fits = glm(diagnosis ~.-ID_number,data=wdbc_sub,family="binomial")
car::vif(glm_fits)

glm_fits = glm(diagnosis ~.-ID_number,data=wdbc_train,family="binomial")
car::vif(glm_fits)
# glm_fits REMOVE IN leverage_and_outliers SECTION)
```

## GLM Model - Leverage and Outliers
```{r leverage_and_outliers}
par(mfrow = c(1, 2))
autoplot(glm_fits, which = 1:6, ncol = 3, label.size = 3, colour = 'diagnosis')
rm(list = c("glm_fits"))
```

## GLM Model Forward - Summary Stats
```{r ModelSummaryStats-Forward}

# TRAIN - TEST DATA
ed.small <- wdbc_train %>% dplyr::select(-1)
glmMod <- glm(diagnosis ~ . , data = ed.small)
fwd_selectedMod_train <- step(glmMod, direction = "forward")
summary(fwd_selectedMod_train)

ed.small <- wdbc_test %>% dplyr::select(-1)
prd<-predict(fwd_selectedMod_train, newdata = ed.small[,2:11])

cutoff <- .3

fwd_predict <- ifelse(prd > cutoff, "Malignant", "Benign")
table(fwd_predict,ed.small$diagnosis)

rm(list = c("ed.small", "glmMod", "fwd_selectedMod_train", "prd", "fwd_predict"))
```

## GLM Model Backward - Summary Stats
```{r ModelSummaryStats-Backward}

# TRAIN - TEST DATA
ed.small <- wdbc_train %>% dplyr::select(-1)
glmMod <- glm(diagnosis ~ . , data = ed.small)
bwd_selectedMod_train <- step(glmMod, direction = "backward")
summary(bwd_selectedMod_train)

ed.small <- wdbc_test %>% dplyr::select(-1)
prd<-predict(bwd_selectedMod_train, newdata = ed.small[,2:11])

bwd_predict <- ifelse(prd > cutoff, "Malignant", "Benign")
table(bwd_predict,ed.small$diagnosis)

rm(list = c("ed.small", "glmMod", "bwd_selectedMod_train", "bwd_predict"))

```

## GLM Model Stepwise - Summary Stats
```{r ModelSummaryStats-Both}

# TRAIN DATA
ed.small <- wdbc_train %>% dplyr::select(-1)
glmMod <- glm(diagnosis ~ . , data = ed.small)
both_selectedMod_train <- step(glmMod, steps = 1000)
summary(both_selectedMod_train)

ed.small <- wdbc_test %>% dplyr::select(-1)
prd<-predict(both_selectedMod_train, newdata = ed.small[,2:11])

both_predict <- ifelse(prd > cutoff, "Malignant", "Benign")
table(both_predict,ed.small$diagnosis)

rm(list = c("ed.small", "glmMod", "both_selectedMod_train", "prd", "both_predict"))

```

## GLM LASSO
```{r ModelSummaryStats-Backward}

# TRAIN DATA
x <- as.matrix(wdbc_train[,-c(1:2)]) # Removes ID and class
y <- as.double(as.matrix(wdbc_train[, 2])) # Only class
# Fitting the model (Lasso: Alpha = 1)
set.seed(12345)
cv.lasso <- cv.glmnet(x, y, family='binomial', alpha=1, parallel=TRUE,
                      standardize=TRUE, type.measure='auc')
# Results
plot(cv.lasso)
plot(cv.lasso$glmnet.fit, xvar="lambda", label=TRUE)
cv.lasso$lambda.min
cv.lasso$lambda.1se
coef(cv.lasso, s=cv.lasso$lambda.min)

ed.small <- wdbc_test %>% dplyr::select(-1)
prd<-predict(both_selectedMod_train, newdata = ed.small[,2:11])

both_predict <- ifelse(prd > cutoff, "Malignant", "Benign")
table(both_predict,ed.small$diagnosis)

rm(list = c("cv.lasso","x", "y"))
```

## Manual Model
```{r ManualModel}
# TRAIN DATA
ed.small <- wdbc_train %>% dplyr::select(diagnosis, area, texture, concave_points)
glmMod <- glm(diagnosis ~ area + texture + concave_points , data = ed.small)
manl_selectedMod_train <- step(glmMod, steps = 1000)
summary(manl_selectedMod_train)

ed.small <- wdbc_test %>% dplyr::select(diagnosis, area, texture, concave_points)
prd<-predict(manl_selectedMod_train, newdata = ed.small[,2:4])

manl_predict <- ifelse(prd > cutoff, "Malignant", "Benign")
table(manl_predict,ed.small$diagnosis)

rm(list = c("ed.small", "glmMod", "manl_selectedMod_train", "prd", "manl_predict"))
```

```{r ModelSelectedAttributes_Pairs}
ed.small <- wdbc_sub %>% dplyr::select(diagnosis, radius, texture, perimeter,
                                       area, concave_points)

cols <- character(nrow(ed.small))
cols[] <- "black"
cols[ed.small$diagnosis == 0] <- "blue"
cols[ed.small$diagnosis == 1] <- "red"
pairs(ed.small, col=cols, main = "WDBC Pairs Plot: Blue = Benign; Red = Malignant")
rm(cols)
rm(ed.small)
```

## GLM Model - Removal of Leverage and Outliers
```{r Remove_Leverage_and_outliers}
wdbc.sub_Not153 <- wdbc.sub[-153,]
wdbc_sub_Not153 <- wdbc_sub[-153,]
```

## MODEL SELECTION
- In stepwise regression, the full model is passed to a *step* function. The stepwise function iteratively searches the full scope of variables.
- The iteration will be performed in a forward and backwards directions.
- In a backward selection, the *step* function performs multiple iteractions by droping one independent variable at a time.  
- In a forward selection, the *step* function performs multiple iteractions by adding one independent variable at a time.
- In each (forward and backward) iteration, multiple models are built and the AIC of the models is computed and the model that yields the lowest AIC is retained for the next iteration.  



```{r StepwiseForwardSelection}
ed.small <- wdbc_sub %>% dplyr::select(-1)
glmMod <- glm(diagnosis ~ . , data = ed.small)
selectedMod <- step(glmMod, direction = "forward")
summary(selectedMod)

# glmMod <- lm(diagnosis ~ . , data = ed.small)
# selectedMod <- step(lmMod, direction = "forward")
# all.vifs <- car::vif(selectedMod)
# print(all.vifs)
```

- When using a forward selection, all nine variables are retained in the model selection.

```{r StepwiseBackwardSelection}
selectedMod <- step(glmMod, direction = "backward")
summary(selectedMod)
rm(list = c("ed.small", "glmMod", "selectedMod"))
```
```{r MISC}
# selectedMod <- step(lmMod, direction = "backward")
# all.vifs <- car::vif(selectedMod)
# print(all.vifs)
# rm(ed.small)
# rm(list = c("ed.small", "lmMod", "all.vifs"))
```
- When using a backward selection, eight variables are retained in the model selection, only Mitoses is omitted from the model selection.

## Logistic Regression
- Following the established discipline of dividing a portion of the dataset into a training set and the remainder into a test set.
- The training set will be used to build the model and the test set will be used to validate the model.
- The training set will consist of 20% of the data and the test set will consist of the remaining 80%.
- A set.seed is used at the beginning of the test and training division in order to get reproducible results.
```{r LogisticRegression}
#wdbc.data.2 <-  wdbc.data %>% mutate(Class2 = case_when(Class == 2 ~ 0,
#                                                        Class == 4 ~ 1)) %>%
# dplyr::select(Clump, Cell_Size, Cell_Shape, Adhesion, Epithelial, Nuclei,
#               Chromatin, Nucleoli, Mitoses, Class = Class2)

#wdbc.data.2$Class <- as.factor(wdbc.data.2$Class)

# #set.seed(12345) #to get repeatable data
# 
# ##wdbc.train <- sample_frac(ed.small, 0.2, replace = FALSE)
# #wdbc.train <- sample_frac(wdbc.data.2, 0.2, replace = FALSE)

#train.index <- as.numeric(rownames(wdbc.train))
##wdbc.test <- ed.small[-train.index,]
#wdbc.test <- wdbc.data.2[-train.index,]

#rm(train.index)

## MODEL FITTING
## wdbc.glm.fit <- glm(CancerState ~ ., data = wdbc.train, family = binomial(link = "logit"))
## wdbc.glm.fit <- glm(CancerState ~ ., data = wdbc.train, family = "binomial")
#wdbc.glm.fit <- glm(Class ~ ., data = wdbc.train, family = "binomial")
#summary(wdbc.glm.fit)
```

Assessing Model Fit:

The following attributes are NOT statistically significant:  
* Cell_Size  
* Epithelial  
  
The following attributes ARE statistically significant:  
* Clump  
* Nuclei  
* Chromatin  
* Adhesion  
* Cell_Shape  
* Mitoses  
  
- In this logit model, the response valirable (CancerState) is log odds, a unit increase in Clump increases the odds by 0.6, a unit increase in Nuclei increases the odds by 0.4, and a unit increase in Chromatin increases the odds by 0.5.
- The null deviance (the deviance just for the mean) is 1271 and the residual deviance (the deviance for the model) is 171.
- The difference between the null deviance and the residual deviance shows how the model is doing against the null model (a model with only the intercept). The wider the gap between the null deviance and the residual deviance, the better.
- Analyzing the table we can see the drop in deviance when adding each variable one at a time, with the exception of when adding Nuclei and Chromatin.
- With the addition of Clump significantly reduces the residual deviance and each additional attribute reduces the residual deviance, but in much smaller increments.

```{r GLM_FIT_ANOVA}
#anova(wdbc.glm.fit, test = "Chisq")
```

Assessing Table of Deviance (ToD):

From the ToD we are able to see the difference between the null deviance versus the residual deviance.  The ToD shows how our model is doing against the null model, which is a model with only the intercept. The wider this gap between the model versus the null, the better.

By adding Clump and Cell_Size to the model drastically reduces the residual deviance.  All attributes have 0.05 p-value or less.

Eventhough there is not an exact equivalent to the R2 of linear regression, the McFadden R2 index can be used to assess the model fit:
```{r ModelFit}
#pr2_mc <- pR2(wdbc.glm.fit)
#pr2_mc[[4]]
```

Assessing the predictive ability of the logistic regression model by predicting from test dataset using against the training dataset:
- The predict function provides probabilities of classification
- Using a probabilities from the predict function, the ifelse will use the threshold of 0.5 to assign classification of "Malignant ", else it will assign a classification of "Benign"
- A confusion matrix will provide how well the model is doing
```{r PredictTest}
#glm.probs <- predict(wdbc.glm.fit, wdbc.test, type = "response")

#prediction(glm.probs, wdbc.test$Class) -> pred_log

#performance(pred_log, "acc") -> acc
#plot(acc) 
#plot(glm.probs)

## MAX Accuracy ~ 0.1
## Confusion Matrix Using Max Accuracy
#x <- table(wdbc.test$Class,glm.probs > 0.6)
#x

## Accuracy when using Max Accuracy Cutoff is:
#(x[1] + x[4])/(x[1] + x[2] + x[3] + x[4])

## TP and FP Rates When Using Max Accuracy Cutoff when cutoff:
## TP Rate:
#x[4]/(x[4] + x[2])
## FP Rate:
#x[3]/(x[3] + x[1])

## Build ROC to get good tradoff between Accuracy and TP/FP Rate
#performance(pred_log, "tpr", "fpr") -> roc_curve
#plot(roc_curve, colorize=T)

#glm.pred <- ifelse(glm.probs > 0.39, "Malignant ","Benign")

## We are attempting to predict CancerState variabel in the dataset, this is used to evaluate what ## is predicted in the model to the actual state
# attach(wdbc.test)
# table(glm.pred,Class)

```
- The confusion matrix operates on the diagonial where the model predicted **CORRECTLY**, starting at the top left (726) and the bottom right (335).
- The off diagonial is where the model predicted **INCORRECTLY**, starting at the bottom left (39) and the top right (18).
- Out of 1118 records, the model had 1070 accurate predictions for an accuracy rate of 95%

# Bruce's Work Ends Here

# Rick's Work Starts Here

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}

```

# Rick's Work Ends Here

#TQ's Work Starts Here


##Proportions

```{r proportions}
#attach(entire.dataset)
##table of counts
# ftable(addmargins(table(CancerState, Clump)))
# ftable(addmargins(table(CancerState, Cell_Size)))
# ftable(addmargins(table(CancerState, Cell_Shape)))
# ftable(addmargins(table(CancerState, Adhesion)))
# ftable(addmargins(table(CancerState, Epithelial)))
# ftable(addmargins(table(CancerState, Nuclei)))
# ftable(addmargins(table(CancerState, Chromatin)))
# ftable(addmargins(table(CancerState, Nucleoli)))
# ftable(addmargins(table(CancerState, Mitoses)))

##in proprtions
# prop.table(table(CancerState, Clump),2)
# prop.table(table(CancerState, Cell_Size),2)
# prop.table(table(CancerState, Cell_Shape),2)
# prop.table(table(CancerState, Adhesion),2)
# prop.table(table(CancerState, Epithelial),2)
# prop.table(table(CancerState, Nuclei),2)
# prop.table(table(CancerState, Chromatin),2)
# prop.table(table(CancerState, Nucleoli),2)
# prop.table(table(CancerState, Mitoses),2)

##vizualize 
# plot(CancerState~Clump,col=c("red","blue"))
# plot(CancerState~Cell_Shape,col=c("red","blue"))
# plot(CancerState~Cell_Size,col=c("red","blue"))
# plot(CancerState~Adhesion,col=c("red","blue"))
# plot(CancerState~Epithelial,col=c("red","blue"))
# plot(CancerState~Nuclei,col=c("red","blue"))
# plot(CancerState~Chromatin,col=c("red","blue"))
# plot(CancerState~Nucleoli,col=c("red","blue"))
# plot(CancerState~Mitoses,col=c("red","blue"))

```

## PCA

```{r PCA}
# pc.result<-prcomp(entire.dataset[,2:11],scale.=TRUE)
# pc.scores<-pc.result$x
# pc.scores<-data.frame(pc.scores)
# pc.scores$Class<-entire.dataset$Class

##Scree plot
# eigenvals<-(pc.result$sdev)^2
# plot(1:10,eigenvals/sum(eigenvals),type="l",main="Scree Plot PC's",ylab="Prop. Var. Explained",ylim=c(0,1))
# cumulative.prop<-cumsum(eigenvals/sum(eigenvals))
# lines(1:10,cumulative.prop,lty=2)


#Use ggplot2 to plot the first few pc's
# ggplot(data = pc.scores, aes(x = PC1, y = PC2)) +
#   geom_point(aes(col=Class), size=1)+
#   ggtitle("PCA of Cancer Status")
# 
# ggplot(data = pc.scores, aes(x = PC2, y = PC3)) +
#   geom_point(aes(col=Class), size=1)+
#   ggtitle("PCA of Cancer Status")
# 
# ggplot(data = pc.scores, aes(x = PC1, y = PC3)) +
#   geom_point(aes(col=Class), size=1)+
#   ggtitle("PCA of Cancer Status")
```
## Separation

PC1 vs PC2 and PC1 vs PC3 show good separation so some variable is a good predictor of cancer status.


## LDA & QDA

```{r LDA_QDA}

# mylda<- lda(Class ~ Clump+Cell_Size+Cell_Shape+Adhesion+Epithelial+Nuclei+Chromatin+Nucleoli+Mitoses, data = entire.dataset)
# myqda<- qda(Class ~ Clump+Cell_Size+Cell_Shape+Adhesion+Epithelial+Nuclei+Chromatin+Nucleoli+Mitoses, data = entire.dataset)

##confusion matrix
# set.seed(2134)
# index<-sample(1:385,250,replace=FALSE)
# test.entire.dataset<-entire.dataset[-index,]
# prd<-predict(mylda, newdata = test.entire.dataset)$class
# table(prd,test.entire.dataset$Class)

##ROC
#ldaprd<-predict(mylda, newdata = entire.dataset)$posterior
##correcting for the way lda creates predicted probabilities
#ldaprd<-ldaprd[,2]

# pred <- prediction(ldaprd, entire.dataset$Class)
# roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
# auc.train <- performance(pred, measure = "auc")
# auc.train <- auc.train@y.values

##Plot ROC
# plot(roc.perf,main="LDA")
# abline(a=0, b= 1) #Ref line indicating poor performance
# text(x = .40, y = .6,paste("AUC = ", round(auc.train[[1]],3), sep = ""))
```


## Stepwise Regression

```{r stepwise}
#?lm

#full.model <- lm (Class ~., data = entire.dataset)
```

## LDA

```{r LDA}
# entire.dataset.continuous <- entire.dataset[, c(2:11)]
# pairs(entire.dataset.continuous[,1:10])

```


#TQ's Work Ends Here